{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Collecting numpy>=1.19.5\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (PEP 517): started\n",
      "  Building wheel for scikit-surprise (PEP 517): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp38-cp38-win_amd64.whl size=1297767 sha256=694fb3cded548453337d931683dbe754dd8271cb67e3b855983ef8233bca9387\n",
      "  Stored in directory: c:\\users\\ruiqi\\appdata\\local\\pip\\cache\\wheels\\99\\34\\23\\b19f7de7352af5d1913f2654641432d6740c2666eecf2472ea\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: numpy, scipy, joblib, scikit-surprise\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.17.0\n",
      "    Uninstalling joblib-0.17.0:\n",
      "      Successfully uninstalled joblib-0.17.0\n",
      "Successfully installed joblib-1.4.2 numpy-1.24.4 scikit-surprise-1.1.4 scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "#from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "#from sklearn import linear_model\n",
    "import warnings\n",
    "from surprise import SVDpp, Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2-cp38-cp38-win_amd64.whl (752 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\ruiqi\\anaconda3\\lib\\site-packages (from implicit) (1.24.4)\n",
      "Requirement already satisfied: threadpoolctl in c:\\users\\ruiqi\\anaconda3\\lib\\site-packages (from implicit) (2.1.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ruiqi\\anaconda3\\lib\\site-packages (from implicit) (4.50.2)\n",
      "Requirement already satisfied: scipy>=0.16 in c:\\users\\ruiqi\\anaconda3\\lib\\site-packages (from implicit) (1.10.1)\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.1-cp38-cp38-win_amd64.whl (1.9 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-intel==2.13.1; platform_system == \"Windows\" (from tensorflow) (from versions: 0.0.1, 2.10.0.dev20220728, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0)\n",
      "ERROR: No matching distribution found for tensorflow-intel==2.13.1; platform_system == \"Windows\" (from tensorflow)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from implicit import bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userIDs = {}\n",
    "bookIDs = {}\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "    if not l[0] in userIDs: userIDs[l[0]] = len(userIDs)\n",
    "    if not l[1] in bookIDs: bookIDs[l[1]] = len(bookIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "usersPerBook = defaultdict(set) # Maps an item to the users who rated it\n",
    "booksPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    usersPerBook[b].add(u)\n",
    "    booksPerUser[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u47877739', 'b50020691', 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsValid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseenPerUser = defaultdict(list)\n",
    "#uniqueUser = []\n",
    "for u in userIDs: #for every user   \n",
    "    for b in bookIDs: #find a book\n",
    "            if u not in booksPerUser or b not in booksPerUser[u]: #the user hasn't seen\n",
    "                unseenPerUser[u].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsValidNeg = []\n",
    "numpy.random.seed(0)\n",
    "for u,b,r in ratingsValid:\n",
    "    ratingsValidNeg.append((u,b,1)) #has read\n",
    "    unseenList = unseenPerUser[u]\n",
    "    bookNum = numpy.random.randint(len(unseenList))\n",
    "    ratingsValidNeg.append((u, unseenList[bookNum], 0)) #has not read\n",
    "random.shuffle(ratingsValidNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ytest = [v[2] for v in ratingsValidNeg]\n",
    "for l in ratingsValidNeg:\n",
    "    if l[1] in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "threshold = totalRead/4*3\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > threshold: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## predict read #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xui = scipy.sparse.lil_matrix((len(userIDs), len(bookIDs)))\n",
    "for d in allRatings:\n",
    "    Xui[userIDs[d[0]],bookIDs[d[1]]] = 1\n",
    "    \n",
    "Xui_csr = scipy.sparse.csr_matrix(Xui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8688c1113381409b98a8c51fcafb1be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = bpr.BayesianPersonalizedRanking(factors = 5)\n",
    "model.fit(Xui_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended = model.recommend(0, Xui_csr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1089,  431,    2, 1388,  490, 2633,  695,  328, 1105,  329]),\n",
       " array([0.74203694, 0.73789394, 0.7362339 , 0.731352  , 0.70485634,\n",
       "        0.6932037 , 0.66025555, 0.65771985, 0.65729755, 0.65431243],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = open(\"predictions_Read.csv\", 'w')\n",
    "# for l in open(\"pairs_Read.csv\"):\n",
    "#     if l.startswith(\"userID\"):\n",
    "#         predictions.write(l)\n",
    "#         continue\n",
    "#     u,b = l.strip().split(',')\n",
    "#     maxSim=0\n",
    "# #     if u in userIDs and b in bookIDs and len(ratingsPerUser[u])>1:\n",
    "# #         ids, score = model.recommend(userIDs[u], Xui_csr[userIDs[u]], N=len(ratingsPerUser[u])/2)\n",
    "# #         for i,s in zip(ids, score):\n",
    "# #             if i==bookIDs[b]:\n",
    "# #                 if s>0.5:\n",
    "# #                     predictions.write(u + ',' + b + \",1\\n\")\n",
    "# #                 else:\n",
    "# #                     predictions.write(u + ',' + b + \",0\\n\")\n",
    "# #                 continue\n",
    "    \n",
    "    \n",
    "#     users = set(ratingsPerItem[b])\n",
    "#     for b2,_ in ratingsPerUser[u]:\n",
    "#         sim = Jaccard(users, set(ratingsPerItem[b2]))\n",
    "#         if sim>maxSim:\n",
    "#             maxSim = sim\n",
    "#     if (maxSim > 0.013) or b in return1 or len(ratingsPerItem[b])>40:\n",
    "#         predictions.write(u + ',' + b + \",1\\n\")\n",
    "#     else:\n",
    "#         predictions.write(u + ',' + b + \",0\\n\")\n",
    "\n",
    "# predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### final implementation ###########################################\n",
    "\n",
    "scorePerUser = defaultdict(list)\n",
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    maxSim=0\n",
    "#     if u in userIDs and b in bookIDs and len(ratingsPerUser[u])>1:\n",
    "#         ids, score = model.recommend(userIDs[u], Xui_csr[userIDs[u]], N=len(ratingsPerUser[u])/2)\n",
    "#         for i,s in zip(ids, score):\n",
    "#             if i==bookIDs[b]:\n",
    "#                 if s>0.5:\n",
    "#                     predictions.write(u + ',' + b + \",1\\n\")\n",
    "#                 else:\n",
    "#                     predictions.write(u + ',' + b + \",0\\n\")\n",
    "#                 continue\n",
    "    \n",
    "    \n",
    "    users = set(ratingsPerItem[b])\n",
    "    for b2,_ in ratingsPerUser[u]:\n",
    "        sim = Jaccard(users, set(ratingsPerItem[b2]))\n",
    "        if sim>maxSim:\n",
    "            maxSim = sim\n",
    "    scorePerUser[u].append((maxSim, b))\n",
    "    \n",
    "for u in scorePerUser:\n",
    "    scorePerUser[u].sort(key=lambda tup: tup[0], reverse=True)  \n",
    "    count = 0\n",
    "    for scores,b in scorePerUser[u]:\n",
    "        if (count < int(len(scorePerUser[u])/2)) and (scores>0.015) or b in return1 or len(ratingsPerItem[b])>50:\n",
    "            predictions.write(u + ',' + b + \",1\\n\")\n",
    "        else: \n",
    "            predictions.write(u + ',' + b + \",0\\n\")\n",
    "        count += 1\n",
    "        \n",
    "# for l in open(\"pairs_Read.csv\"):\n",
    "#     if l.startswith(\"userID\"):\n",
    "#         predictions.write(l)\n",
    "#         continue\n",
    "#     u,b = l.strip().split(',')\n",
    "#     maxSim=0\n",
    "#     median = scorePerUser[u][int(len(scorePerUser[u])/2)]\n",
    "#     users = set(ratingsPerItem[b])\n",
    "#     for b2,_ in ratingsPerUser[u]:\n",
    "#         sim = Jaccard(users, set(ratingsPerItem[b2]))\n",
    "#         if sim>maxSim:\n",
    "#             maxSim = sim\n",
    "    \n",
    "#     if (maxSim >= median):\n",
    "#         predictions.write(u + ',' + b + \",1\\n\")\n",
    "#     else:\n",
    "#         predictions.write(u + ',' + b + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ratingsValid and ratingsTrain\n",
    "reader = Reader(line_format='user item rating', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file(\"train_Interactions.csv\", reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVDpp' object has no attribute 'bu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-c98355f7fdbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mminBeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmaxBeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0muserIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mminUser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_raw_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmaxUser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_raw_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVDpp' object has no attribute 'bu'"
     ]
    }
   ],
   "source": [
    "minBeta = model.bu[0]\n",
    "maxBeta = model.bu[0]\n",
    "userIndex = 0\n",
    "minUser = trainset.to_raw_uid(0)\n",
    "maxUser = trainset.to_raw_uid(0)\n",
    "\n",
    "for u in trainset.all_users():\n",
    "    b = model.bu[userIndex]\n",
    "    if b<minBeta:\n",
    "        minBeta = b\n",
    "        minUser = trainset.to_raw_uid(u)\n",
    "    if b>maxBeta:\n",
    "        maxBeta = b\n",
    "        maxUser = trainset.to_raw_uid(u)\n",
    "    userIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = []\n",
    "lambdas = [0.008, 0.01, 0.013]\n",
    "for lr in lambdas:\n",
    "    model = SVDpp(reg_all=0.08, n_factors=3, lr_all=0.0075, lr_bu=0.007, lr_pu=lr, init_std_dev=0.053)\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    sse = 0\n",
    "    for p in predictions:\n",
    "        sse += (p.r_ui - p.est)**2\n",
    "    mses.append(sse / len(predictions))\n",
    "\n",
    "validMSE = mses[0]\n",
    "lamb = lambdas[0]\n",
    "for (m,l) in zip(mses, lambdas):\n",
    "    if m<validMSE:\n",
    "        validMSE = m\n",
    "        lamb = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.008, 1.4697120786577704)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lamb, validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05, 1.4469116716494959)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'][0])\n",
    "assertFloat(answers['Q8'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVDpp(reg_all=0.11, n_factors=3, lr_all=0.0075, n_epochs=100)\n",
    "model.fit(trainset)\n",
    "Rui = trainset.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## predict rating #########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
    "    pred = model.predict(u, b, r_ui=Rui)\n",
    "    predictions.write(u + ',' + b + ',' + str(pred.est) + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"{u'username': u'Chaos Syren', u'hours': 0.1, u'products': 41, u'product_id': u'725280', u'page_order': 0, u'date': u'2017-12-17', u'text': u'This would not be acceptable as an entertainment even back in the day when these graphics were all there was to be had. No effort has been made to bring the player into any story or even entertain.', u'early_access': False, u'page': 1}\\n\"\n"
     ]
    }
   ],
   "source": [
    "f = gzip.open(\"steam_reviews.json.gz\")\n",
    "#dataset = []\n",
    "for i, l in enumerate(f):\n",
    "    if i==0:\n",
    "        print(l)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
