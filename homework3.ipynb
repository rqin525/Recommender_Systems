{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Collecting numpy>=1.19.5\n",
      "  Downloading numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (PEP 517): started\n",
      "  Building wheel for scikit-surprise (PEP 517): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp38-cp38-win_amd64.whl size=1297767 sha256=694fb3cded548453337d931683dbe754dd8271cb67e3b855983ef8233bca9387\n",
      "  Stored in directory: c:\\users\\ruiqi\\appdata\\local\\pip\\cache\\wheels\\99\\34\\23\\b19f7de7352af5d1913f2654641432d6740c2666eecf2472ea\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: numpy, scipy, joblib, scikit-surprise\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.2\n",
      "    Uninstalling numpy-1.19.2:\n",
      "      Successfully uninstalled numpy-1.19.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.17.0\n",
      "    Uninstalling joblib-0.17.0:\n",
      "      Successfully uninstalled joblib-0.17.0\n",
      "Successfully installed joblib-1.4.2 numpy-1.24.4 scikit-surprise-1.1.4 scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "import numpy\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "from surprise import SVD, Reader, Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userIDs = {}\n",
    "bookIDs = {}\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "    if not l[0] in userIDs: userIDs[l[0]] = len(userIDs)\n",
    "    if not l[1] in bookIDs: bookIDs[l[1]] = len(bookIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "usersPerBook = defaultdict(set) # Maps an item to the users who rated it\n",
    "booksPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))\n",
    "    usersPerBook[b].add(u)\n",
    "    booksPerUser[u].add(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('u47877739', 'b50020691', 4)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsValid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseenPerUser = defaultdict(list)\n",
    "#uniqueUser = []\n",
    "for u in userIDs: #for every user   \n",
    "    for b in bookIDs: #find a book\n",
    "            if u not in booksPerUser or b not in booksPerUser[u]: #the user hasn't seen\n",
    "                unseenPerUser[u].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsValidNeg = []\n",
    "numpy.random.seed(0)\n",
    "for u,b,r in ratingsValid:\n",
    "    ratingsValidNeg.append((u,b,1)) #has read\n",
    "    unseenList = unseenPerUser[u]\n",
    "    bookNum = numpy.random.randint(len(unseenList))\n",
    "    ratingsValidNeg.append((u, unseenList[bookNum], 0)) #has not read\n",
    "random.shuffle(ratingsValidNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ytest = [v[2] for v in ratingsValidNeg]\n",
    "for l in ratingsValidNeg:\n",
    "    if l[1] in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([predi and yi for (predi, yi) in zip(predictions, ytest)])\n",
    "TN = sum([(predi==False and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FP = sum([(predi==True and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FN = sum([(predi==False and yi==True) for (predi, yi) in zip(predictions, ytest)])\n",
    "acc1 = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71265"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "threshold = totalRead/4*3\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > threshold: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "ytest = [v[2] for v in ratingsValidNeg]\n",
    "for l in ratingsValidNeg:\n",
    "    if l[1] in return1:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([predi and yi for (predi, yi) in zip(predictions, ytest)])\n",
    "TN = sum([(predi==False and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FP = sum([(predi==True and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FN = sum([(predi==False and yi==True) for (predi, yi) in zip(predictions, ytest)])\n",
    "acc2 = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q2'] = [threshold, acc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[150000.0, 0.7541]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for u,b,_ in ratingsValidNeg:\n",
    "    similarities = []\n",
    "    for b2 in booksPerUser[u]:\n",
    "        sim = Jaccard(usersPerBook[b], usersPerBook[b2])\n",
    "        similarities.append(sim)\n",
    "    similarities.sort(reverse=True)\n",
    "    if (similarities and similarities[0] > 0.0025): #threshold\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([predi and yi for (predi, yi) in zip(predictions, ytest)])\n",
    "TN = sum([(predi==False and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FP = sum([(predi==True and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FN = sum([(predi==False and yi==True) for (predi, yi) in zip(predictions, ytest)])\n",
    "acc3 = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for u,b,_ in ratingsValidNeg:\n",
    "    similarities = []\n",
    "    for b2 in booksPerUser[u]:\n",
    "        sim = Jaccard(usersPerBook[b], usersPerBook[b2])\n",
    "        similarities.append(sim)\n",
    "    similarities.sort(reverse=True)\n",
    "    if b in return1 or (similarities and similarities[0] > 0.0025): #threshold\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = sum([predi and yi for (predi, yi) in zip(predictions, ytest)])\n",
    "TN = sum([(predi==False and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FP = sum([(predi==True and yi==False) for (predi, yi) in zip(predictions, ytest)])\n",
    "FN = sum([(predi==False and yi==True) for (predi, yi) in zip(predictions, ytest)])\n",
    "acc4 = (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = acc3\n",
    "answers['Q4'] = acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6999, 0.71285]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[acc3, acc4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    similarities = []\n",
    "    for b2 in booksPerUser[u]:\n",
    "        sim = Jaccard(usersPerBook[b], usersPerBook[b2])\n",
    "        similarities.append(sim)\n",
    "    similarities.sort(reverse=True)\n",
    "    if b in return1 or (similarities and similarities[0] > 0.0025): #threshold\n",
    "        predictions.write(u + ',' + b + \",1\\n\")\n",
    "    else:\n",
    "        predictions.write(u + ',' + b + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ratingsValid and ratingsTrain\n",
    "reader = Reader(line_format='user item rating', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file(\"train_Interactions.csv\", reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rui = sum([r for _,_,r in ratingsTrain]) / len(ratingsTrain)\n",
    "# ytest = [v[2] for v in ratingsValid]\n",
    "# init\n",
    "# alpha = Rui\n",
    "# betaU = random.uniform(0, 0.001, len(userIDs))\n",
    "# betaI = random.uniform(0, 0.001, len(bookIDs))\n",
    "# lamb = 1.0\n",
    "# def predict(u,i):\n",
    "#     return alpha + betaU[u] + betaI[i]\n",
    "# def reg():\n",
    "#     return lamb * (sum([u**2 for u in betaU]) + sum([i**2 for i in betaI]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = 0\n",
    "for p in predictions:\n",
    "    sse += (p.r_ui - p.est)**2\n",
    "\n",
    "validMSE = sse / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute alpha and betas to minimize sum of squared errors SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q6'] = validMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.461951228601719"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "minBeta = model.bu[0]\n",
    "maxBeta = model.bu[0]\n",
    "userIndex = 0\n",
    "minUser = trainset.to_raw_uid(0)\n",
    "maxUser = trainset.to_raw_uid(0)\n",
    "\n",
    "for u in trainset.all_users():\n",
    "    b = model.bu[userIndex]\n",
    "    if b<minBeta:\n",
    "        minBeta = b\n",
    "        minUser = trainset.to_raw_uid(u)\n",
    "    if b>maxBeta:\n",
    "        maxBeta = b\n",
    "        maxUser = trainset.to_raw_uid(u)\n",
    "    userIndex += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [maxUser, minUser, maxBeta, minBeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u79275096', 'u89636398', 1.2202710630549345, -3.0431915326992804]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [type(x) for x in answers['Q7']] == [str, str, float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = []\n",
    "lambdas = [0.0001, 0.005, 0.001, 0.05, 0.01]\n",
    "for reg in lambdas:\n",
    "    model = SVD(reg_all=reg)\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    sse = 0\n",
    "    for p in predictions:\n",
    "        sse += (p.r_ui - p.est)**2\n",
    "    mses.append(sse / len(predictions))\n",
    "\n",
    "validMSE = mses[0]\n",
    "lamb = lambdas[0]\n",
    "for (m,l) in zip(mses, lambdas):\n",
    "    if m<validMSE:\n",
    "        validMSE = m\n",
    "        lamb = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = (lamb, validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05, 1.4469116716494959)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'][0])\n",
    "assertFloat(answers['Q8'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVD(reg_all=0.05)\n",
    "model.fit(trainset)\n",
    "Rui = trainset.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
    "    pred = model.predict(u, b, r_ui=Rui)\n",
    "    predictions.write(u + ',' + b + ',' + str(pred.est) + '\\n')\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
